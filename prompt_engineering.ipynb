{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXqKrqPkaBP8fFgILYJfDk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyominleee/prompt_engineering/blob/main/prompt_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kQXJ-dcSdkjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 프롬프트 평가 (MT - Bench)"
      ],
      "metadata": {
        "id": "Bj-SBvlmdVP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7flWV9kHUWJ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2q_EJN-Im0D",
        "outputId": "0f707378-4b96-413a-b67f-f55585cece5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.86.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "Openai_API_Key = userdata.get('OPEN_AI_KEY')\n",
        "\n",
        "client = OpenAI(api_key=Openai_API_Key)\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo-0125',\n",
        "    messages = [{'role' : 'user', 'content' : '배고프다'}],\n",
        "    temperature = 1.0\n",
        "    )\n",
        "\n",
        "print (completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiXEScfZIxvK",
        "outputId": "5c8cc097-25db-417b-b9a4-ee9083970325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "뭘 먹고 싶으세요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pucIO0oQLm8K",
        "outputId": "c6b36fc5-5692-4998-fd26-ded136425843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-BjktFcX5sJgqyOCB2n5Z6v3CVA3oc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='뭘 먹고 싶으세요?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1750244705, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=13, total_tokens=25, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo-0125',\n",
        "    messages = [{'role' : 'assistant', 'content': '당신은 초등학교 과학 선생님입니다. 초등학생의 질문에 눈높이에 맞게 친절히 답해주세요.'},\n",
        "        {'role' : 'user', 'content' : '아기는 어떻게 만들어져요?'}],\n",
        "    temperature = 1.0\n",
        ")\n",
        "\n",
        "print (completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5IKI9B3Qjez",
        "outputId": "1e5a1d11-e677-436f-8dea-37019219707c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아기는 엄마와 아빠가 사랑을 나누어서 만들어져요. 엄마의 배속에 있는 작은 알이 아빠의 정자와 만나서 아기가 만들어져요. 이 작은 알은 엄마의 자궁 안에서 성장하고 아기가 태어날 때까지 엄마의 몸속에서 성장하게 됩니다. 아기가 성장하면 엄마의 배속에서 태어나서 우리가 보는 아기가 되는 거죠. 생명이라는 것은 정말 신비로운 일이에요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo-0125',\n",
        "    messages = [{'role' : 'assistant', 'content': '아주 친한 친구랑 대화하듯이 말해주세요.'}\n",
        "        {'role' : 'user', 'content' : '배고프다'}],\n",
        "    temperature = 1.0\n",
        "    stream = True\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print (chunk.choices[0].delta.content or '', end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXZqZWNysRHc",
        "outputId": "31b0e95d-de2d-47bb-a4a6-e81457189f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "그럼 뭘 먹을래? 같이 뭐 좀 먹을까?"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = '니체의 신은 죽었다는 어떤 의미야?'\n",
        "\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo-0125',\n",
        "    messages = [{'role' : 'user', 'content': question}],\n",
        "    temperature = 0.0\n",
        ")\n",
        "\n",
        "answer_a = completion.choices[0].message.content\n",
        "\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model = 'gpt-4-0613',\n",
        "    messages = [{'role' : 'user', 'content': question}],\n",
        "    temperature = 0.0\n",
        ")\n",
        "\n",
        "answer_b = completion.choices[0].message.content\n",
        "\n",
        "\n",
        "prompt = f\"\"\"[System]\n",
        "Please act as an impartial judge and evaluate the quality of the responses provided by two\n",
        "AI assistants to the user question displayed below. You should choose the assistant that\n",
        "follows the user’s instructions and answers the user’s question better. Your evaluation\n",
        "should consider factors such as the helpfulness, relevance, accuracy, depth, creativity,\n",
        "and level of detail of their responses. Begin your evaluation by comparing the two\n",
        "responses and provide a short explanation. Avoid any position biases and ensure that the\n",
        "order in which the responses were presented does not influence your decision. Do not allow\n",
        "the length of the responses to influence your evaluation. Do not favor certain names of\n",
        "the assistants. Be as objective as possible. After providing your explanation, output your\n",
        "final verdict by strictly following this format: \"[[A]]\" if assistant A is better, \"[[B]]\"\n",
        "if assistant B is better, and \"[[C]]\" for a tie. Translate your explanation into Korean.\n",
        "\n",
        "[User Question]\n",
        "{question}\n",
        "\n",
        "[The Start of Assistant A’s Answer]\n",
        "{answer_a}\n",
        "[The End of Assistant A’s Answer]\n",
        "\n",
        "[The Start of Assistant B’s Answer]\n",
        "{answer_b}\n",
        "[The End of Assistant B’s Answer]\"\"\"\n",
        "\n",
        "print(prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkb51xYxtI-c",
        "outputId": "3ff725ec-e3f8-4fd7-b729-a57e355da0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[System]\n",
            "Please act as an impartial judge and evaluate the quality of the responses provided by two\n",
            "AI assistants to the user question displayed below. You should choose the assistant that\n",
            "follows the user’s instructions and answers the user’s question better. Your evaluation\n",
            "should consider factors such as the helpfulness, relevance, accuracy, depth, creativity,\n",
            "and level of detail of their responses. Begin your evaluation by comparing the two\n",
            "responses and provide a short explanation. Avoid any position biases and ensure that the\n",
            "order in which the responses were presented does not influence your decision. Do not allow\n",
            "the length of the responses to influence your evaluation. Do not favor certain names of\n",
            "the assistants. Be as objective as possible. After providing your explanation, output your\n",
            "final verdict by strictly following this format: \"[[A]]\" if assistant A is better, \"[[B]]\"\n",
            "if assistant B is better, and \"[[C]]\" for a tie. Translate your explanation into Korean.\n",
            "\n",
            "[User Question]\n",
            "니체의 신은 죽었다는 어떤 의미야?\n",
            "\n",
            "[The Start of Assistant A’s Answer]\n",
            "\"니체의 신은 죽었다\"는 말은 실제로 니체의 책 '참된 철학의 탄생'에서 나온 문구입니다. 이는 종교적인 신을 믿는 사람들이 점차적으로 신을 버리고 자신의 삶과 가치를 스스로 찾아야 한다는 의미를 담고 있습니다. 니체는 종교적인 신을 버리고 인간 중심의 철학을 제시하며, 자기 존재의 의미와 가치를 스스로 찾아야 한다고 주장했습니다. 따라서 \"니체의 신은 죽었다\"는 말은 종교적인 신을 버리고 자기 존재와 가치를 스스로 찾아야 한다는 의미를 갖고 있습니다.\n",
            "[The End of Assistant A’s Answer]\n",
            "\n",
            "[The Start of Assistant B’s Answer]\n",
            "\"신은 죽었다\"는 문구는 독일의 철학자 프리드리히 니체가 그의 작품들에서 사용한 유명한 주장입니다. 이 문구는 종교적인 신의 존재를 부정하는 것이 아니라, 니체가 지적하고자 하는 것은 서구 사회에서 신의 권위와 영향력이 사라졌다는 것입니다.\n",
            "\n",
            "니체는 이를 통해 사람들이 전통적인 도덕과 가치를 더 이상 신의 교리에 의존하지 않고, 자신들 스스로의 이유와 판단에 의해 도덕과 가치를 결정하게 될 것이라는 점을 강조하고자 했습니다. 이는 인간의 자유와 독립성을 강조하는 니체의 철학적 입장을 반영하는 것이기도 합니다.\n",
            "\n",
            "또한, \"신은 죽었다\"는 주장은 신이 죽었으므로 이제는 사람들이 자신들의 삶과 세상을 지배하고, 자신들의 가치를 창조해야 한다는 니체의 '초인' 개념으로 이어집니다.\n",
            "[The End of Assistant B’s Answer]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model='gpt-4-turbo-2024-04-09',\n",
        "    messages=[{'role': 'user', 'content': prompt}],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGDvBTkz9xs5",
        "outputId": "4cf216a9-f746-4404-fdfe-a50638fcbb3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "비교 분석:\n",
            "\n",
            "두 응답 모두 니체의 \"신은 죽었다\"라는 문구의 의미를 설명하는 데 있어 정확하고 유익합니다. 그러나 두 응답의 접근 방식과 제공된 정보의 깊이에서 차이가 있습니다.\n",
            "\n",
            "A의 응답은 니체의 주장이 종교적 신을 버리고 인간 중심의 철학을 제시한다는 점을 강조합니다. 이는 니체의 철학적 입장을 간결하게 전달하며, 신의 죽음이 개인의 자율성과 자기 가치 발견의 중요성을 강조한다는 점을 명확히 합니다.\n",
            "\n",
            "B의 응답은 좀 더 포괄적이며, 니체의 철학적 배경과 그의 주장이 서구 사회에서 신의 권위와 영향력의 상실을 어떻게 반영하는지에 대해 설명합니다. 또한, 니체의 '초인' 개념과 그것이 어떻게 인간의 자유와 독립성을 강조하는지에 대해서도 언급합니다. 이는 니체의 주장의 광범위한 철학적 맥락을 제공하며, 독자에게 더 깊은 이해를 제공합니다.\n",
            "\n",
            "종합적으로, B의 응답은 니체의 주장을 더 넓은 철학적 맥락에서 설명하고, 그 의미의 다양한 측면을 탐구함으로써 더욱 풍부하고 상세한 정보를 제공합니다. A의 응답도 유익하지만, B의 응답이 더 많은 배경 정보와 철학적 깊이를 제공한다는 점에서 우위를 점합니다.\n",
            "\n",
            "최종 판결: [[B]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p2FFt8WMSNc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 뉴스 요약 평가 (G-Eval / ROUGE)"
      ],
      "metadata": {
        "id": "SbS3Cl-9dv8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news = \"\"\"SK바이오팜이 미국 실리콘밸리의 인공지능(AI) 스타트업 피닉스랩과 전략적 업무협약(MOU)을 체결하고 AI 기반 신약 개발 체계 구축에 본격적으로 나섰다고 18일 밝혔다.\n",
        "\n",
        "양사는 피닉스랩의 생성형 AI 솔루션 ‘케이론’을 기반으로 신약 개발 과정에서 필요한 문헌 검색, 데이터 분석, 문서 작성 등을 자동화하는 맞춤형 솔루션을 공동 개발할 예정이다.\n",
        "\n",
        "특히 임상 진입 단계 때 필요한 허가 서류 작성 등의 업무 자동화를 중심으로 신약 개발 과정을 AI 기반으로 전환하는 작업에 속도를 낼 방침이다.\n",
        "\n",
        "SK바이오팜은 연구개발(R&D) 생산성을 극대화하고 개발 및 허가에 소요되는 시간과 비용을 획기적으로 줄일 수 있을 것으로 기대한다.\n",
        "\n",
        "케이론은 기업 내외부 학술 데이터를 통합 분석해 문헌 조사부터 보고서 작성까지 모든 과정을 자동화할 수 있도록 한다.\n",
        "\n",
        "또 식품의약품안전처, 미국 식품의약국(FDA) 등 주요 규제 기관의 공식 데이터베이스와 의학 학술정보 분류 체계로 제약·바이오 산업에 특화해 정확도와 실효성을 높인 것이 특징이다.\n",
        "\n",
        "SK바이오팜은 기존에도 자체 AI 플랫폼 ‘허블’을 이용해 질병 유발 유전자 및 단백질 분석, 후보물질 발굴 등 신약 개발 초기 단계에 AI를 적극 활용해왔다.\n",
        "\n",
        "이동훈 SK바이오팜 사장은 “신약 개발 과정에 AI 적용을 강화하겠다”고 말했다.\"\"\""
      ],
      "metadata": {
        "id": "qzQfghW6p2wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"아래 뉴스 기사를 3줄로 요약해줘.\n",
        "\n",
        "{news}\n",
        "\"\"\"\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "summary_gpt3 = completion.choices[0].message.content\n",
        "\n",
        "print (\"summary_gpt3\")\n",
        "\n",
        "for line in summary_gpt3.split('.'):\n",
        "    print(line)\n",
        "\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-0613\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "summary_gpt4 = completion.choices[0].message.content\n",
        "\n",
        "print (\"summary_gpt4\")\n",
        "\n",
        "for line in summary_gpt4.split('.'):\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xynhFkFvd8pA",
        "outputId": "0e80033a-608e-485b-8baa-ae159c46f241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary_gpt3\n",
            "SK바이오팜이 미국 AI 스타트업과 MOU를 체결해 AI 기반 신약 개발에 나섰다\n",
            " 양사는 케이론을 기반으로 신약 개발 과정을 자동화하는 맞춤형 솔루션을 공동 개발할 예정이다\n",
            " SK바이오팜은 AI를 활용해 연구개발 생산성을 높이고 시간과 비용을 절감할 것으로 기대된다\n",
            "\n",
            "summary_gpt4\n",
            "SK바이오팜이 미국의 AI 스타트업 피닉스랩과 협약을 맺고 AI 기반 신약 개발에 나선다\n",
            " 피닉스랩의 AI 솔루션 '케이론'을 활용해 신약 개발 과정에서 필요한 문헌 검색, 데이터 분석, 문서 작성 등을 자동화하는 솔루션을 공동 개발할 계획이다\n",
            " 이를 통해 연구개발 생산성을 극대화하고 개발 및 허가에 소요되는 시간과 비용을 줄일 수 있을 것으로 기대한다\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompt = f\"\"\"You will be given one summary written for a news article.\n",
        "Your task is to rate the summary on one metric.\n",
        "Please make sure you read and understand these instructions carefully. Please keep this\n",
        "document open while reviewing, and refer to it as needed.\n",
        "Evaluation Criteria:\n",
        "Coherence (1-5) - the collective quality of all sentences. We align this dimension with\n",
        "the DUC quality question of structure and coherence whereby ”the summary should be\n",
        "well-structured and well-organized. The summary should not just be a heap of related information, but should build from sentence to sentence to a coherent body of information about a topic.”\n",
        "Evaluation Steps:\n",
        "1. Read the news article carefully and identify the main topic and key points.\n",
        "2. Read the summary and compare it to the news article. Check if the summary covers the main\n",
        "topic and key points of the news article, and if it presents them in a clear and logical order.\n",
        "3. Assign a score for coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest\n",
        "based on the Evaluation Criteria.\n",
        "Example:\n",
        "Source Text:\n",
        "{news}\n",
        "Summary:\n",
        "{summary_gpt3}\n",
        "Evaluation Form (scores ONLY):\n",
        "- Coherence:\"\"\"\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo-2024-04-09\",\n",
        "    messages=[{\"role\": \"user\", \"content\": eval_prompt}],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uRY2t2XiJpZ",
        "outputId": "b3bb3719-0b41-47e8-aee6-5212d11824a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompt = f\"\"\"You will be given one summary written for a news article.\n",
        "Your task is to rate the summary on one metric.\n",
        "Please make sure you read and understand these instructions carefully. Please keep this\n",
        "document open while reviewing, and refer to it as needed.\n",
        "Evaluation Criteria:\n",
        "Coherence (1-5) - the collective quality of all sentences. We align this dimension with\n",
        "the DUC quality question of structure and coherence whereby ”the summary should be\n",
        "well-structured and well-organized. The summary should not just be a heap of related information, but should build from sentence to sentence to a coherent body of information about a topic.”\n",
        "Evaluation Steps:\n",
        "1. Read the news article carefully and identify the main topic and key points.\n",
        "2. Read the summary and compare it to the news article. Check if the summary covers the main\n",
        "topic and key points of the news article, and if it presents them in a clear and logical order.\n",
        "3. Assign a score for coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest\n",
        "based on the Evaluation Criteria.\n",
        "Example:\n",
        "Source Text:\n",
        "{news}\n",
        "Summary:\n",
        "{summary_gpt4}\n",
        "Evaluation Form (scores ONLY):\n",
        "- Coherence:\"\"\"\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo-2024-04-09\",\n",
        "    messages=[{\"role\": \"user\", \"content\": eval_prompt}],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAc_StI7rZXC",
        "outputId": "ff0d294d-c4a8-4e69-ed7e-9412f2d681e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Coherence: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge --quiet"
      ],
      "metadata": {
        "id": "JNeIplharfJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary_gpt3, summary_gpt4)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDdlXSRuryLB",
        "outputId": "c6017e6f-d8a9-487b-f909-60696ca7376d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'r': 0.35555555555555557, 'p': 0.5, 'f': 0.4155844107269354},\n",
              "  'rouge-2': {'r': 0.16666666666666666,\n",
              "   'p': 0.24242424242424243,\n",
              "   'f': 0.19753085936899875},\n",
              "  'rouge-l': {'r': 0.35555555555555557, 'p': 0.5, 'f': 0.4155844107269354}}]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"아래 뉴스 기사를 3줄로 요약해줘. 행위의 맥락과 의도, 도구의 쓰임을 자세히 적어줘.\n",
        "\n",
        "{news}\n",
        "\"\"\"\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "summary_gpt3 = completion.choices[0].message.content\n",
        "\n",
        "print (\"summary_gpt3\")\n",
        "\n",
        "for line in summary_gpt3.split('.'):\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXNrdgJ1r4Q2",
        "outputId": "89bea501-ec44-4822-83fa-c025ff1a54f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary_gpt3\n",
            "SK바이오팜이 미국 AI 스타트업과 MOU를 체결해 AI 기반 신약 개발에 나섰다\n",
            " 양사는 ‘케이론’을 기반으로 신약 개발 과정을 자동화하는 맞춤형 솔루션을 공동 개발할 예정이다\n",
            " 특히 임상 진입 단계에서의 업무 자동화를 통해 신약 개발 과정을 AI 기반으로 전환할 계획이다\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"You are a helpful Summarization Assistant. Below is given a news in Korean.\n",
        "Please summarize below news in three sentences. Summary should describe the detailed context of the news.\n",
        "\n",
        "{news}\n",
        "\"\"\"\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "summary_gpt3 = completion.choices[0].message.content\n",
        "\n",
        "print (\"summary_gpt3\")\n",
        "\n",
        "for line in summary_gpt3.split('.'):\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvrZQpzMt2Ru",
        "outputId": "757849e2-16c4-45a9-dc3c-fa2746378f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary_gpt3\n",
            "SK바이오팜은 미국 실리콘밸리의 AI 스타트업 피닉스랩과 MOU를 체결하여 AI 기반 신약 개발에 나섰다\n",
            " 양사는 케이론을 기반으로 신약 개발 과정을 자동화하는 맞춤형 솔루션을 공동 개발할 예정이며, 허가 서류 작성 등의 업무 자동화를 중심으로 신약 개발 과정을 AI 기반으로 전환할 계획이다\n",
            " SK바이오팜은 이를 통해 연구개발 생산성을 극대화하고 시간과 비용을 획기적으로 줄일 것으로 기대하고 있다\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompt = f\"\"\"You will be given one summary written for a news article.\n",
        "Your task is to rate the summary on one metric.\n",
        "Please make sure you read and understand these instructions carefully. Please keep this\n",
        "document open while reviewing, and refer to it as needed.\n",
        "Evaluation Criteria:\n",
        "Coherence (1-5) - the collective quality of all sentences. We align this dimension with\n",
        "the DUC quality question of structure and coherence whereby ”the summary should be\n",
        "well-structured and well-organized. The summary should not just be a heap of related information, but should build from sentence to sentence to a coherent body of information about a topic.”\n",
        "Evaluation Steps:\n",
        "1. Read the news article carefully and identify the main topic and key points.\n",
        "2. Read the summary and compare it to the news article. Check if the summary covers the main\n",
        "topic and key points of the news article, and if it presents them in a clear and logical order.\n",
        "3. Assign a score for coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest\n",
        "based on the Evaluation Criteria.\n",
        "Example:\n",
        "Source Text:\n",
        "{news}\n",
        "Summary:\n",
        "{summary_gpt3}\n",
        "Evaluation Form (scores ONLY):\n",
        "- Coherence:\"\"\"\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo-2024-04-09\",\n",
        "    messages=[{\"role\": \"user\", \"content\": eval_prompt}],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp79gG5PufeD",
        "outputId": "e7284ce6-94e6-4617-bb4b-d7888cdc7ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Coherence: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(summary_gpt3, summary_gpt4)\n",
        "scores"
      ],
      "metadata": {
        "id": "7vceQf5Zu3T3",
        "outputId": "83309c99-f197-47fd-ff0c-c884e69c9332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'r': 0.4888888888888889, 'p': 0.5, 'f': 0.49438201747254135},\n",
              "  'rouge-2': {'r': 0.2708333333333333,\n",
              "   'p': 0.2653061224489796,\n",
              "   'f': 0.26804123211393355},\n",
              "  'rouge-l': {'r': 0.4666666666666667,\n",
              "   'p': 0.4772727272727273,\n",
              "   'f': 0.47191010736018185}}]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "memjUeg8u8Vd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}